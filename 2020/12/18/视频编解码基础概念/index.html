<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <title>
        Alliswell
    </title>
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-reply replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            视频编解码基础概念
        </p>
        <hr>
    </div>
    <div class="post-content">
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>原始图像信息被采集后，视频数据体积非常大，不利于传输和储存，必须进行编码压缩。播放时只需要采用对应的解码技术就可以恢复播放。<br>本文只涉及这个编解码流程中的基础概念、定义等。</p>
<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><blockquote>
<p>以下摘录自<a target="_blank" rel="noopener" href="https://www.cnblogs.com/leisure_chn/p/10285829.html">https://www.cnblogs.com/leisure_chn/p/10285829.html</a></p>
</blockquote>
<h3 id="熵与冗余"><a href="#熵与冗余" class="headerlink" title="熵与冗余"></a>熵与冗余</h3><p>引自参考资料[1]第1.5节</p>
<blockquote>
<p>在所有的实际节目素材中，存在着两种类型的信号分量：即异常的、不可预见的信号分量和可以预见的信号分量。异常分量称为<strong>熵</strong>，它是信号中的真正信息。其余部分称为<strong>冗余</strong>，因为它不是必需的信息。冗余可以是空间性的，如在图像的大片区域中，邻近像素几乎具有相同的数值。冗余也可以是时间性的，例如连续图像之间的相似部分。在所有的压缩系统编码器中都是将熵与冗余相分离，只有熵被编码和传输，而在解码器中再从编码器的发送的信号中计算出冗余。</p>
</blockquote>
<h3 id="帧内编码"><a href="#帧内编码" class="headerlink" title="帧内编码"></a>帧内编码</h3><p>帧内编码是空间域编码，利用图像空间性冗余度进行图像压缩，处理的是一幅独立的图像，不会跨越多幅图像。空间域编码依赖于一幅图像中相邻像素间的相似性和图案区的主要空间域频率。</p>
<p>JPEG标准用于静止图像(即图片)，只使用了空间域压缩，只使用帧内编码。</p>
<h3 id="帧间编码"><a href="#帧间编码" class="headerlink" title="帧间编码"></a>帧间编码</h3><p>帧间编码是时间域编码，是利用一组连续图像间的时间性冗余度进行图像压缩。如果某帧图像可被解码器使用，那么解码器只须利用两帧图像的差异即可得到下一帧图像。比如运动平缓的几帧图像的相似性大，差异性小，而运动剧烈的几幅图像则相似性小，差异性大。当得到一帧完整的图像信息后，可以利用与后一帧图像的差异值推算得到后一帧图像，这样就实现了数据量的压缩。时间域编码依赖于连续图像帧间的相似性，尽可能利用已接收处理的图像信息来“预测”生成当前图像。</p>
<p>MPEG标准用于运动图像(即视频)，会使用空间域编码和时间域编码，因此是帧内编码和帧间编码结合使用。</p>
<h3 id="运动矢量"><a href="#运动矢量" class="headerlink" title="运动矢量"></a>运动矢量</h3><p>一组连续图像记录了目标的运动。运动矢量用于衡量两帧图像间目标的运动程度，运动矢量由水平位移量和垂直位移量二者构成。</p>
<h3 id="运动补偿"><a href="#运动补偿" class="headerlink" title="运动补偿"></a>运动补偿</h3><p>目标的运动降低了图像间的相似性，增加了差异数据量。而运动补偿则通过运行矢量来降低图像间的差异数据量。</p>
<p>下图为运动补偿的示意图。当某一目标运动时，其位置会变化但形状颜色等基本不变。编码器则可利用运动矢量减低图像差值，解码器根据图像差值中的运动矢量移动目标到合适的位置即可。假设图中是理想情况，目标除移动位置外其他任何属性无任何变化，则两幅图像间的差值仅包含运动矢量这一数据量。显然运动补偿可以显著减少图像差值数据量。<br><img src="https://leichn.github.io/img/avideo_basics/motion_compensation.jpg" alt="图1 运动补偿"></p>
<h3 id="双向预测"><a href="#双向预测" class="headerlink" title="双向预测"></a>双向预测</h3><p>先看示意图：<br><img src="https://leichn.github.io/img/avideo_basics/bi-directionally_predicted.jpg" alt="图2 双向预测"></p>
<p>连续的三幅图像中，目标块有垂直位置上的移动，背景块无位置移动。我们考虑如何取得当前帧图像(画面N)：<br>画面N中，目标向上移动后，露出背景块。<br>画面N-1中，因为背景块被目标块遮挡住了，因此没有背景块相关信息。<br>画面N+1中，完整包含背景块的数据，因此画面N可以从画面N-1中取得背景块。<br>如何可以得到画面N呢？解码器可以先解码得到画面N-1和画面N+1，通过画面N-1中的目标块数据结合运动矢量即可得到画面N中的目标块数据，通过画面N+1中的背景块数据则可得到画面N中的背景块数据。三幅画面的解码顺序为：N-1, N+1, N。三幅画面的显示顺序为：N-1, N, N+1。画面N通过其前一幅画面N-1和后一幅画面N+1推算(预测，predicted)得到，因此这种方式称为双向预测(或前向预测、双向参考)。</p>
<h3 id="I帧-IDR帧-P帧-B帧"><a href="#I帧-IDR帧-P帧-B帧" class="headerlink" title="I帧/IDR帧/P帧/B帧"></a>I帧/IDR帧/P帧/B帧</h3><p><strong>I帧</strong>：I帧(Intra-coded picture, 帧内编码帧，常称为关键帧)包含一幅完整的图像信息，属于帧内编码图像，不含运动矢量，在解码时不需要参考其他帧图像。因此在I帧图像处可以切换频道，而不会导致图像丢失或无法解码。I帧图像用于阻止误差的累积和扩散。在闭合式GOP中，每个GOP的第一个帧一定是I帧，且当前GOP的数据不会参考前后GOP的数据。</p>
<p><strong>IDR帧</strong>：IDR帧(Instantaneous Decoding Refresh picture, 即时解码刷新帧)是一种特殊的I帧。当解码器解码到IDR帧时，会将DPB(Decoded Picture Buffer，指前后向参考帧列表)清空，将已解码的数据全部输出或抛弃，然后开始一次全新的解码序列。IDR帧之后的图像不会参考IDR帧之前的图像，因此IDR帧可以阻止视频流中的错误传播，同时IDR帧也是解码器、播放器的一个安全访问点。</p>
<p><strong>P帧</strong>：P帧(Predictive-coded picture, 预测编码图像帧)是帧间编码帧，利用之前的I帧或P帧进行预测编码。</p>
<p><strong>B帧</strong>：B帧(Bi-directionally predicted picture, 双向预测编码图像帧)是帧间编码帧，利用之前和(或)之后的I帧或P帧进行双向预测编码。B帧不可以作为参考帧。<br>B帧具有更高的压缩率，但需要更多的缓冲时间以及更高的CPU占用率，因此B帧适合本地存储以及视频点播，而不适用对实时性要求较高的直播系统。</p>
<h3 id="GOP"><a href="#GOP" class="headerlink" title="GOP"></a>GOP</h3><p>GOP(Group Of Pictures, 图像组)是一组连续的图像，由一个I帧和多个B/P帧组成，是编解码器存取的基本单位。GOP结构常用的两个参数M和N，M指定GOP中两个anchor frame(anchor frame指可被其他帧参考的帧，即I帧或P帧)之间的距离，N指定一个GOP的大小。例如M=3，N=15，GOP结构为：IBBPBBPBBPBBPBB</p>
<p>TODO: GOP中是否每两个anchor frame的间隔是相同的？推测：未必相同。实际上分析不少视频文件，规律并不一致。此处没有彻底弄清楚，待进一步积累素材、分析与确认。</p>
<p>GOP有两种：闭合式GOP和开放式GOP：</p>
<p><strong>闭合式GOP</strong>：闭合式GOP只需要参考本GOP内的图像即可，不需参考前后GOP的数据。这种模式决定了，闭合式GOP的显示顺序总是以I帧开始以P帧结束</p>
<p>TODO: 闭合式GOP是否一定是以P帧结束？推测：可能未必有此定义。有看到某些视频文件GOP以B帧结束。</p>
<p><strong>开放式GOP</strong>：开放式GOP中的B帧解码时可能要用到其前一个GOP或后一个GOP的某些帧。码流里面包含B帧的时候才会出现开放式GOP。</p>
<p>TODO: 开放式GOP是否规定是以B帧开始，P帧结束？推测：可能未必有此定义。是否以B帧开始？网上资料说法不一。是否以P帧结束？有看到某些视频文件GOP以B帧结束。</p>
<p>在开放式GOP中，普通I帧和IDR帧功能是有差别的，需要明确区分两种帧类型。在闭合式GOP中，普通I帧和IDR帧功能没有差别，可以不作区分。</p>
<p>开放式GOP和闭合式GOP中I帧、P帧、B帧的依赖关系如下图所示：<br><img src="https://leichn.github.io/img/avideo_basics/gop_mode.jpg" alt="图3 GOP模式"></p>
<h3 id="DTS和PTS"><a href="#DTS和PTS" class="headerlink" title="DTS和PTS"></a>DTS和PTS</h3><p>DTS(Decoding Time Stamp, 解码时间戳)，表示压缩帧的解码时间。<br>PTS(Presentation Time Stamp, 显示时间戳)，表示将压缩帧解码后得到的原始帧的显示时间。<br>音频中DTS和PTS是相同的。视频中由于B帧需要双向预测，B帧依赖于其前和其后的帧，因此含B帧的视频解码顺序与显示顺序不同，即DTS与PTS不同。当然，不含B帧的视频，其DTS和PTS是相同的。下图以一个开放式GOP示意图为例，说明视频流的解码顺序和显示顺序<br><img src="https://leichn.github.io/img/avideo_basics/decode_order.jpg" alt="图4 解码和显示顺序"><br><strong>采集顺序</strong>指图像传感器采集原始信号得到图像帧的顺序。<br><strong>编码顺序</strong>指编码器编码后图像帧的顺序。存储到磁盘的本地视频文件中图像帧的顺序与编码顺序相同。<br><strong>传输顺序</strong>指编码后的流在网络中传输过程中图像帧的顺序。<br><strong>解码顺序</strong>指解码器解码图像帧的顺序。<br><strong>显示顺序</strong>指图像帧在显示器上显示的顺序。<br><strong>采集顺序与显示顺序相同。编码顺序、传输顺序和解码顺序相同。</strong><br>以图中“B[1]”帧为例进行说明，“B[1]”帧解码时需要参考“I[0]”帧和“P[3]”帧，因此“P[3]”帧必须比“B[1]”帧先解码。这就导致了解码顺序和显示顺序的不一致，后显示的帧需要先解码。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<p>[1] 泰克Tektronic, MPEG基础和协议分析指南<br>[2] <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/04b5b1e4ff27">视频直播的理论知识</a>，<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/04b5b1e4ff27">https://www.jianshu.com/p/04b5b1e4ff27</a><br>[3] <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d30c051b4106">open GOP &amp; close GOP</a>, <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d30c051b4106">https://www.jianshu.com/p/d30c051b4106</a><br>[4] <a target="_blank" rel="noopener" href="https://blog.csdn.net/abcsunl/article/details/68190136">I帧/B帧/P帧/GOP</a>, <a target="_blank" rel="noopener" href="https://blog.csdn.net/abcsunl/article/details/68190136">https://blog.csdn.net/abcsunl/article/details/68190136</a><br>[5] <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3578e794f6b5">FFmpeg音视频同步原理与实现</a>, <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3578e794f6b5">https://www.jianshu.com/p/3578e794f6b5</a><br>[6] <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/27279255f67e">FFmpeg音视频同步</a>, <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/27279255f67e">https://www.jianshu.com/p/27279255f67e</a><br>[7] <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S1319157819301867">The GOP Inter Prediction of H.264 AVC</a>, <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S1319157819301867">https://www.sciencedirect.com/science/article/pii/S1319157819301867</a><br>[8] <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Group_of_pictures">WiKi Group of pictures</a>, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Group_of_pictures">https://en.wikipedia.org/wiki/Group_of_pictures</a><br>[9] <a target="_blank" rel="noopener" href="https://streaminglearningcenter.com/articles/open-and-closed-gops-all-you-need-to-know.html">Open and Closed GOPs – All You Need to Know</a>, <a target="_blank" rel="noopener" href="https://streaminglearningcenter.com/articles/open-and-closed-gops-all-you-need-to-know.html">https://streaminglearningcenter.com/articles/open-and-closed-gops-all-you-need-to-know.html</a></p>
</blockquote>

    </div>

    
        <hr class="fhr">
        <div id="vcomments"></div>
    
</div>
    <div class="footer" id="footer">
    <p>Copyright © 2020 <a class="flink" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>-<a class="flink" target="_blank" rel="noopener" href="https://github.com/sanjinhub/hexo-theme-geek">Geek</a>.
        <label class="el-switch el-switch-green el-switch-sm" style="vertical-align: sub;">
            <input type="checkbox" name="switch" id="update_style">
            <span class="el-switch-style"></span>
        </label>
<!--         <script type="text/javascript">
        var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
        document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
        </script> -->
    </p>
</div>
<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="ueIePJtaGryN9FhXJieFg0zv-MdYXbMMI">
<input type="hidden" id="valine_appKey" value="YrCpNBNF8jxrR28HotIjP2Gb">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
    color: #698fca;
}

.v .vlist .vcard .vhead .vsys {
    color: #3a3e4a;
}

.v .vlist .vcard .vh .vmeta .vat {
    color: #638fd5;
}

.v .vlist .vcard .vhead .vnick {
    color: #6ba1ff;
}

.v a {
    color: #8696b1;
}

.v .vlist .vcard .vhead .vnick:hover {
    color: #669bfc;
}
</style>
</body>

</html>